# Copyright 2016 Dennis Vriend
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# the akka-persistence-journal in use
jdbc-journal {
  class = "akka.persistence.jdbc.journal.JdbcAsyncWriteJournal"
}

# the akka-persistence-snapshot-store in use
jdbc-snapshot-store {
  class = "akka.persistence.jdbc.snapshot.JdbcSnapshotStore"
}

# the akka-persistence-query provider in use
jdbc-read-journal {
  class = "akka.persistence.jdbc.query.journal.JdbcReadJournalProvider"
}

akka-persistence-jdbc {

  inMemory = off
  inMemoryTimeout = 5s

  slick {
    driver = "slick.driver.PostgresDriver"
    db {
      host = "boot2docker"
      host = ${?POSTGRES_HOST}
      port = "5432"
      port = ${?POSTGRES_PORT}
      name = "docker"

      url = "jdbc:postgresql://"${akka-persistence-jdbc.slick.db.host}":"${akka-persistence-jdbc.slick.db.port}"/"${akka-persistence-jdbc.slick.db.name}
      user = "docker"
      password = "docker"
      driver = "org.postgresql.Driver"

      // hikariCP settings; see: https://github.com/brettwooldridge/HikariCP

      // read: https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing
      // slick will use an async executor with a fixed size queue of 10.000 objects
      // The async executor is a connection pool for asynchronous execution of blocking I/O actions.
      // This is used for the asynchronous query execution API on top of blocking back-ends like JDBC.
      queueSize = 10000 // number of objects that can be queued by the async exector

      connectionTimeout = 30000 // This property controls the maximum number of milliseconds that a client (that's you) will wait for a connection from the pool. If this time is exceeded without a connection becoming available, a SQLException will be thrown. 1000ms is the minimum value. Default: 30000 (30 seconds)
      validationTimeout = 5000 // This property controls the maximum amount of time that a connection will be tested for aliveness. This value must be less than the connectionTimeout. The lowest accepted validation timeout is 1000ms (1 second). Default: 5000
      idleTimeout = 600000 // 10 minutes: This property controls the maximum amount of time that a connection is allowed to sit idle in the pool. Whether a connection is retired as idle or not is subject to a maximum variation of +30 seconds, and average variation of +15 seconds. A connection will never be retired as idle before this timeout. A value of 0 means that idle connections are never removed from the pool. Default: 600000 (10 minutes)
      maxLifetime = 1800000 // 30 minutes: This property controls the maximum lifetime of a connection in the pool. When a connection reaches this timeout it will be retired from the pool, subject to a maximum variation of +30 seconds. An in-use connection will never be retired, only when it is closed will it then be removed. We strongly recommend setting this value, and it should be at least 30 seconds less than any database-level connection timeout. A value of 0 indicates no maximum lifetime (infinite lifetime), subject of course to the idleTimeout setting. Default: 1800000 (30 minutes)
      leakDetectionThreshold = 0 // This property controls the amount of time that a connection can be out of the pool before a message is logged indicating a possible connection leak. A value of 0 means leak detection is disabled. Lowest acceptable value for enabling leak detection is 2000 (2 secs). Default: 0

      initializationFailFast = true // This property controls whether the pool will "fail fast" if the pool cannot be seeded with initial connections successfully. If you want your application to start even when the database is down/unavailable, set this property to false. Default: true

      keepAliveConnection = on // ensures that the database does not get dropped while we are using it

      numThreads = 4 // number of cores
      maxConnections = 10 // 2 * numThreads + 1 (if running on an SSD)
      minConnections = 4  // same as numThreads
    }
  }

  tables {
    journal {
      tableName = "journal"
      schemaName = ""
      columnNames {
        persistenceId = "persistence_id"
        sequenceNumber = "sequence_number"
        created = "created"
        tags = "tags"
        message = "message"
      }
    }

    deletedTo {
      tableName = "deleted_to"
      schemaName = ""
      columnNames = {
        persistenceId = "persistence_id"
        deletedTo = "deleted_to"
      }
    }

    snapshot {
      tableName = "snapshot"
      schemaName = ""
      columnNames {
        persistenceId = "persistence_id"
        sequenceNumber = "sequence_number"
        created = "created"
        snapshot = "snapshot"
      }
    }
  }

  query {
    separator = ","
  }

  serialization {
    journal = on // alter only when using a custom dao
    snapshot = on // alter only when using a custom dao
  }

  // Custom dao implementations. Akka Persistence uses the DefaultJournalDao and
  // custom DefaultSnapshotDao. These dao implementations serialize the data model to byte
  // arrays that will be stored in the persistency store.
  // By creating your own custom JournalDao and/or custom SnapshotDao, how the data will be
  // persisted can be changed. For example, the default implementation stores the events and snapshots
  // as a blob in a serialized array, but it is possible to change this strategy and store the events
  // in multiple tables, eg. one EventLog table, that stores the persistenceId, sequenceNumber and event
  // identifier (Discriminator field). The event data will be stored in another table. This strategy stores
  // the events in a typed manner. Of course, the dao must implement all necessary administration so that
  // akka persistence can do its job.
  dao {
    journal = "akka.persistence.jdbc.dao.bytea.ByteArrayJournalDao"
    snapshot = "akka.persistence.jdbc.dao.bytea.ByteArraySnapshotDao"
  }
}
